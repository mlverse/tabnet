---
title: "Using ROC AUM loss for imbalanced binary classification"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Using ROC AUM loss for imbalanced binary classification}
  %\VignetteEngine{quarto::htm}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(tabnet)
library(tidymodels)
library(modeldata)
data("lending_club", package = "modeldata")
```

::: {.callout-note}
This vignette is a continuation of `vignette("tidymodels-interface")`. So we highly encourage you to start with it to be up to speed with this vignette here.
:::

## Introduction

The previously used `lending_club` dataset is highly imbalanced binary classification task. Despite we got fairly good accuracy with default model design, the roc_auc metric was poor due to this imbalanced problem.

Here we will see how tabnet feature allows improved performance on such familly of classification problems. 

## How imbalance is my problem ? 

The target variable `Class` imbalance can be evaluated through the class imbalance Ratio : 
```{r}
class_ratio <- lending_club |> 
  summarise(sum( Class == "good") / sum( Class == "bad")) |> 
  pull() 

class_ratio
```
With a class_ratio of `r format(class_ratio, digits = 3)`, the target variable is seriously imbalanced, making the minority class much harder to model.

## Solutions to improve imbalanced classification models

First usual solution to that problem is over-sampling of the minority class, and/or down-sampling the majority class in the training data. We won't cover this here. 

The second solution is case weighting. As {tidymodels} offers the framework to manage such case weighting, we'll first use it to compare two model family - xgboost and tabnet - with that feature.

Then we would like to **optimize** the model according to the metric we are looking at. As the metric of choice for imbalanced dataset are `roc_auc()` or `roc_pr()`, we definitively want a loss function that is o proxy of those. This is available in {tabnet} with the `nn_aum_loss()` from [Optimizing ROC Curves with a Sort-Based Surrogate Loss for Binary Classification and Changepoint Detection (J Hillman, TD Hocking)](https://jmlr.org/papers/v24/21-0751.html).

## Using the AUC metric and `pr_curve()` plots

Measuring the ROC_AUC or AUC_PR can be separated from plotting the pr_curve.

Let's baseline our models on two different workflows, one for tabnet, one for XGBoost: 
```{r}
lending_club <- lending_club |>
  mutate(
    case_wts = if_else(Class == "bad", class_ratio, 1),
    case_wts = importance_weights(case_wts)
  )

split <- initial_split(lending_club, strata = Class)
train <- training(split)
test  <- testing(split)

tab_rec <- train |>
  recipe() |>
  update_role(Class, new_role = "outcome") |>
  update_role(-has_role(c("outcome", "id", "case_weights")), new_role = "predictor")

xgb_rec <- tab_rec |> 
  step_dummy(term, sub_grade, addr_state, verification_status, emp_length)

tab_mod <- tabnet(epochs = 100) |> 
  set_engine("torch", device = "cpu") |> 
  set_mode("classification")

xgb_mod <- boost_tree(trees = 100) |> 
  set_engine("xgboost") |> 
  set_mode("classification")

tab_wf <- workflow() |> 
  add_model(tab_mod) |> 
  add_recipe(tab_rec) |> 
  add_case_weights(case_wts)

xgb_wf <- workflow() |> 
  add_model(xgb_mod) |> 
  add_recipe(xgb_rec) |> 
  add_case_weights(case_wts)
```

We can now fit each model and plot the precision-recall curve on the test-set : 

```{r}
#| label: "vanilia models fitting"
#| layout-ncol: 2
#| fig-cap: 
#|   - "Tabnet, no case-weight, default loss"
#|   - "XGBoost, no case-weight"
#| fig-cap-location: "top" 
tab_fit <- tab_wf |> fit(train)
xgb_fit <- xgb_wf |> fit(train)

tab_test <- tab_fit |> augment(test)
xgb_test <- xgb_fit |> augment(test)

tab_test |> 
  pr_curve(Class, .pred_good) |> 
  autoplot() +
  theme(plot.title = element_text(size = 9))

xgb_test |>
  pr_curve(Class, .pred_good) |>
  autoplot() +
  theme(plot.title = element_text(size = 9))

```


## Case-weight

Weighting each observation by the importance weight of the class is made available in {tabnet} through   
-   marking one variable as importance weight variable via `workflow::add_case_weights()` 
-   using the case_weight variable as such at inference time through the `case_weights = ` parameter in functions that allows it.

Let's proceed 
```{r}
#| label: "case-weights prediction"
#| layout-ncol: 2
#| fig-cap: 
#|   - "Tabnet, with case-weight, default loss"
#|   - "XGBoost, with case-weight"
#| fig-cap-location: "top" 
tab_test |> 
  pr_curve(Class, .pred_good, case_weights = case_wts) |> 
  autoplot() +
  theme(plot.title = element_text(size = 9))

xgb_test |>
  pr_curve(Class, .pred_good, case_weights = case_wts) |>
  autoplot() +
  theme(plot.title = element_text(size = 9))
```

## ROC_AUM loss

{tabnet} implement the ROC AUM loss that will drive the torch optimizer to the best possible AUC. Let's use it to compare to previous models : 
```{r}
#| label: "AUM based model fit"
# configure the AUM loss
tab_aum_mod <- tabnet(epochs = 100, loss = tabnet::nn_aum_loss, learn_rate = 0.02) |> 
  set_engine("torch", device = "cpu") |> 
  set_mode("classification")

# derive a workflow
tab_aum_wf <- workflow() |> 
  add_model(tab_aum_mod) |> 
  add_recipe(tab_rec) |> 
  add_case_weights(case_wts)

# fit and aument the test dataset with prediction
tab_aum_fit <- tab_aum_wf |> fit(train)
tab_aum_test <- tab_aum_fit |> augment(test)
```

Now let's compare the result on the PR curve with the default loss side by side: 
```{r}
#| label: "AUM model pr_curve"
#| layout-ncol: 2
#| fig-cap: 
#|   - "Tabnet, no case-weight, default loss"
#|   - "Tabnet, no case-weight, ROC_AUM loss"
#| fig-cap-location: "top" 
tab_test |> 
  pr_curve(Class, .pred_good) |> 
  autoplot() +
  theme(plot.title = element_text(size = 9))


tab_aum_test |> 
  pr_curve(Class, .pred_good) |> 
  autoplot() +
  theme(plot.title = element_text(size = 9))

```

## All together

```{r}
#| label: "AUM and case-weights prediction"
#| layout-ncol: 2
#| fig-cap: 
#|   - "Tabnet, with case-weight, default loss"
#|   - "Tabnet, with case-weight, ROC_AUM loss"
#| fig-cap-location: "top" 
tab_test |> 
  pr_curve(Class, .pred_good, case_weights = case_wts) |> 
  autoplot() +
  theme(plot.title = element_text(size = 9))


tab_aum_test |> 
  pr_curve(Class, .pred_good, case_weights = case_wts) |> 
  autoplot() +
  theme(plot.title = element_text(size = 9))

```

