<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Training a Tabnet model from missing-values dataset • tabnet</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js" integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Training a Tabnet model from missing-values dataset">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">


    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">tabnet</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">0.6.0.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Articles

    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/Hierarchical_classification.html">Hierarchical Classification</a>
    </li>
    <li>
      <a href="../articles/interpretation.html">Interpretation tools</a>
    </li>
    <li>
      <a href="../articles/Missing_data_predictors.html">Training a Tabnet model from missing-values dataset</a>
    </li>
    <li>
      <a href="../articles/selfsupervised_training.html">Self-supervised training and fine-tuning</a>
    </li>
    <li>
      <a href="../articles/tidymodels-interface.html">Fitting tabnet with tidymodels</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/mlverse/tabnet/" class="external-link">
    <span class="fab fa-github fa-lg"></span>

  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->



      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Training a Tabnet model from missing-values
dataset</h1>
                        <h4 data-toc-skip class="author">Christophe
Regouby</h4>
            
            <h4 data-toc-skip class="date">2024-07-29</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/mlverse/tabnet/blob/main/vignettes/Missing_data_predictors.Rmd" class="external-link"><code>vignettes/Missing_data_predictors.Rmd</code></a></small>
      <div class="hidden name"><code>Missing_data_predictors.Rmd</code></div>

    </div>

    
    
<div class="section level2">
<h2 id="motivation">Motivation<a class="anchor" aria-label="anchor" href="#motivation"></a>
</h2>
<p>Real-life training dataset usually contains missing data. The vast
majority of deep-learning networks do not handle missing data and thus
either stop or crash when values are missing in the predictors.</p>
<p>But Tabnet use a masking mechanism that we can reuse to cover the
missing data in the training set.</p>
<p>As we enter the world of missing-data, we have to question the type
of missing-data we deal with. We could have missing data at random
(MAR), like for example some transmission errors on a sensor data
dataset, or missing not at random (MNAR) when some interactions exists
between the missing data and other predictors values for the same
sample. The later is a more complex topic to cover, and we will try to
investigate it here through the <code>ames</code> dataset.</p>
</div>
<div class="section level2">
<h2 id="missing-data-dataset-creation">Missing-data dataset creation<a class="anchor" aria-label="anchor" href="#missing-data-dataset-creation"></a>
</h2>
<div class="section level3">
<h3 id="ames-missings-understanding">Ames missings understanding<a class="anchor" aria-label="anchor" href="#ames-missings-understanding"></a>
</h3>
<p>The <code>ames</code> dataset from <a href="https://modeldata.tidymodels.org" class="external-link">modeldata</a> contains
a lot of <em>null values</em> that the human analysis clearly understand
as an implicit <em>“missing object”</em> described by that value. We
have for example pool surface of 0 square meters means “no pool”,
basement surface of 0 square meters means “no basement”, …<br>
Many of those variables can be detected visually by inspecting the
distribution of the values like, for example, the
<code>Masonry veneer area</code> predictor :</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://tidymodels.tidymodels.org" class="external-link">tidymodels</a></span>, quietly <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://mlverse.github.io/tabnet/" class="external-link">tabnet</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"ames"</span>, package <span class="op">=</span> <span class="st">"modeldata"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/qplot.html" class="external-link">qplot</a></span><span class="op">(</span><span class="va">ames</span><span class="op">$</span><span class="va">Mas_Vnr_Area</span><span class="op">)</span></span></code></pre></div>
<p><img src="ames_mas_vnr_hist.png" alt="ames variable Mas_Vnr_Area histogram showing high occurrence of value zero">
We know that it will be extremely difficult for a model to capture an
internal representation of such distribution, and thus we want to avoid
the null values to penalize the model internal representation.</p>
</div>
<div class="section level3">
<h3 id="while-keeping-some-room-for-freedom">While keeping some room for freedom<a class="anchor" aria-label="anchor" href="#while-keeping-some-room-for-freedom"></a>
</h3>
<p>Many of those variables come as a pair in the <code>ames</code>
dataset, one for the qualitative aspect, the other for the quantitative
aspect. We have for example <code>Pool_QC</code> for pool condition,
that has a “no_pool” level with <code>Pool_Area=0</code> in that
case.<br>
As human, we have the intuition that knowing if a pool is present is
important for the modeling task. So we want the model to get an internal
representation of the implicit <code>has_pool=FALSE</code> without
having it explicit in the dataset. In order to do so, we have to let the
model some freedom to infer the “no_pool” state and thus we should not
mutate both variables in the pair <code>Pool_Area=NA</code> and
<code>Pool_QC=NA</code> at the same time.</p>
</div>
<div class="section level3">
<h3 id="ames-with-missing-data">Ames with missing data<a class="anchor" aria-label="anchor" href="#ames-with-missing-data"></a>
</h3>
<p>Let’s turn those missing objects data explicitly into
<code>NAs</code> in an new <code>ames_missing</code> dataset :</p>
<p>A quick and dirty way to achieve this on numerical predictors is to
<code><a href="https://dplyr.tidyverse.org/reference/na_if.html" class="external-link">na_if()</a></code> zeros on any column which name is related to
surface and area.<br>
Then, according to the keep room for freedom rule, do it carefully on
the matching categorical predictors</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">col_with_zero_as_na</span> <span class="op">&lt;-</span> <span class="va">ames</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html" class="external-link">select</a></span><span class="op">(</span><span class="fu"><a href="https://tidyselect.r-lib.org/reference/where.html" class="external-link">where</a></span><span class="op">(</span><span class="va">is.numeric</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html" class="external-link">select</a></span><span class="op">(</span><span class="fu"><a href="https://tidyselect.r-lib.org/reference/starts_with.html" class="external-link">matches</a></span><span class="op">(</span><span class="st">"_SF|Area|Misc_Val|[Pp]orch$"</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise_each.html" class="external-link">summarise_each</a></span><span class="op">(</span><span class="va">min</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select_all.html" class="external-link">select_if</a></span><span class="op">(</span><span class="op">~</span><span class="va">.x</span><span class="op">==</span><span class="fl">0</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">ames_missing</span> <span class="op">&lt;-</span> <span class="va">ames</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate_all.html" class="external-link">mutate_at</a></span><span class="op">(</span><span class="va">col_with_zero_as_na</span>, <span class="va">na_if</span>, <span class="fl">0</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate_all.html" class="external-link">mutate_at</a></span><span class="op">(</span><span class="st">"Alley"</span>, <span class="va">na_if</span>, <span class="st">"No_Alley_Access"</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate_all.html" class="external-link">mutate_at</a></span><span class="op">(</span><span class="st">"Fence"</span>, <span class="va">na_if</span>, <span class="st">"No_Fence"</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate_all.html" class="external-link">mutate_at</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Garage_Cond"</span>, <span class="st">"Garage_Finish"</span><span class="op">)</span>, <span class="va">na_if</span>, <span class="st">"No_Garage"</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate_all.html" class="external-link">mutate_at</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Bsmt_Exposure"</span>, <span class="st">"BsmtFin_Type_1"</span>, <span class="st">"BsmtFin_Type_2"</span><span class="op">)</span>, <span class="va">na_if</span>, <span class="st">"No_Basement"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">visdat</span><span class="fu">::</span><span class="fu"><a href="https://docs.ropensci.org/visdat/reference/vis_miss.html" class="external-link">vis_miss</a></span><span class="op">(</span><span class="va">ames_missing</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="vis_miss_ames.png" alt="ames missing values visualization showing few variables with more than 90% missingness with a global 13% missing"><div class="figcaption">ames missing values visualization showing few
variables with more than 90% missingness with a global 13% missing</div>
</div>
<p>We can see here that variable are not missing at random, and thus we
can expect the model to capture the missingness relation during the
pretraining phase.</p>
<p>Note: A better way to achieve proper value mutation to explicit NAs
would be to also check if the qualitative column in the pair refers to
<code>none</code> or to zero occurrence of the equipment. But this is
beyond the scope of this vignette.</p>
</div>
</div>
<div class="section level2">
<h2 id="model-pretraining">Model pretraining<a class="anchor" aria-label="anchor" href="#model-pretraining"></a>
</h2>
<p>Let’s pretrain one model for each of those dataset, and analyze
variable importance that emerge after the unsupervised representation
learning step:</p>
<div class="section level3">
<h3 id="variable-importance-with-raw-ames-dataset">Variable importance with raw <code>ames</code> dataset<a class="anchor" aria-label="anchor" href="#variable-importance-with-raw-ames-dataset"></a>
</h3>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ames_rec</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://recipes.tidymodels.org/reference/recipe.html" class="external-link">recipe</a></span><span class="op">(</span><span class="va">Sale_Price</span> <span class="op">~</span> <span class="va">.</span>, data<span class="op">=</span><span class="va">ames</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://recipes.tidymodels.org/reference/step_normalize.html" class="external-link">step_normalize</a></span><span class="op">(</span><span class="fu"><a href="https://recipes.tidymodels.org/reference/has_role.html" class="external-link">all_numeric</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">cat_emb_dim</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html" class="external-link">map_dbl</a></span><span class="op">(</span><span class="va">ames</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select_all.html" class="external-link">select_if</a></span><span class="op">(</span><span class="va">is.factor</span><span class="op">)</span>, <span class="op">~</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log2</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nlevels.html" class="external-link">nlevels</a></span><span class="op">(</span><span class="va">.x</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="va">round</span><span class="op">)</span></span>
<span></span>
<span><span class="va">ames_pretrain</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/tabnet_pretrain.html">tabnet_pretrain</a></span><span class="op">(</span><span class="va">ames_rec</span>, data<span class="op">=</span><span class="va">ames</span>,  epoch<span class="op">=</span><span class="fl">50</span>, cat_emb_dim <span class="op">=</span> <span class="va">cat_emb_dim</span>,</span>
<span>                            valid_split <span class="op">=</span> <span class="fl">0.2</span>, verbose<span class="op">=</span><span class="cn">TRUE</span>, batch<span class="op">=</span><span class="fl">2930</span>, </span>
<span>                            early_stopping_patience <span class="op">=</span> <span class="fl">3L</span>, early_stopping_tolerance <span class="op">=</span> <span class="fl">1e-4</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html" class="external-link">autoplot</a></span><span class="op">(</span><span class="va">ames_pretrain</span><span class="op">)</span></span></code></pre></div>
<pre><code>[Epoch 001] Loss: 43.708794 Valid loss: 8066126.500000
[Epoch 002] Loss: 31.463089 Valid loss: 5631984.000000
[Epoch 003] Loss: 23.396217 Valid loss: 3901085.500000
[Epoch 004] Loss: 19.241619 Valid loss: 2947481.750000
[Epoch 005] Loss: 15.032537 Valid loss: 2250338.000000
[Epoch 006] Loss: 12.991020 Valid loss: 1815583.125000
[Epoch 007] Loss: 11.044646 Valid loss: 1533597.875000
[Epoch 008] Loss: 9.114124 Valid loss: 1395840.000000
[Epoch 009] Loss: 8.362211 Valid loss: 1258169.375000
[Epoch 010] Loss: 7.549719 Valid loss: 1064599.500000
[Epoch 011] Loss: 6.808529 Valid loss: 998335.625000
[Epoch 012] Loss: 6.569450 Valid loss: 1047418.500000
[Epoch 013] Loss: 6.606429 Valid loss: 1048583.625000
[Epoch 014] Loss: 6.742617 Valid loss: 993241.312500
[Epoch 015] Loss: 6.806847 Valid loss: 995705.875000
[Epoch 016] Loss: 6.618536 Valid loss: 1026789.625000
[Epoch 017] Loss: 6.593469 Valid loss: 1033726.437500
Early stopping at epoch 017</code></pre>
<div class="float">
<img src="ames_pretrain.png" alt="ames_fit model training diagnostic plot"><div class="figcaption">ames_fit model training diagnostic plot</div>
</div>
<p>Now we capture the columns with missings, and create a convenience
function to color the <code><a href="https://koalaverse.github.io/vip/reference/vip.html" class="external-link">vip::vip()</a></code> plot output according to
the missingness quality of the column</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">col_with_missings</span> <span class="op">&lt;-</span> <span class="va">ames_missing</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise_all.html" class="external-link">summarise_all</a></span><span class="op">(</span><span class="op">~</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/NA.html" class="external-link">is.na</a></span><span class="op">(</span><span class="va">.</span><span class="op">)</span><span class="op">)</span><span class="op">&gt;</span><span class="fl">0</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="va">t</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/enframe.html" class="external-link">enframe</a></span><span class="op">(</span>name<span class="op">=</span><span class="st">"Variable"</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/rename.html" class="external-link">rename</a></span><span class="op">(</span>has_missing<span class="op">=</span><span class="st">"value"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">vip_color</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">object</span>, <span class="va">col_has_missing</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">vip_data</span> <span class="op">&lt;-</span> <span class="fu">vip</span><span class="fu">::</span><span class="fu"><a href="https://koalaverse.github.io/vip/reference/vip.html" class="external-link">vip</a></span><span class="op">(</span><span class="va">object</span><span class="op">)</span><span class="op">$</span><span class="va">data</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/arrange.html" class="external-link">arrange</a></span><span class="op">(</span><span class="va">Importance</span><span class="op">)</span></span>
<span>  <span class="va">vis_miss_plus</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate-joins.html" class="external-link">left_join</a></span><span class="op">(</span><span class="va">vip_data</span>, <span class="va">col_has_missing</span> , by<span class="op">=</span><span class="st">"Variable"</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>Variable<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">factor</a></span><span class="op">(</span><span class="va">Variable</span>, levels <span class="op">=</span> <span class="va">vip_data</span><span class="op">$</span><span class="va">Variable</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">vis_miss_plus</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">vis_miss_plus</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">Variable</span>, y<span class="op">=</span><span class="va">Importance</span>, fill<span class="op">=</span><span class="va">has_missing</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_bar.html" class="external-link">geom_col</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/coord_flip.html" class="external-link">coord_flip</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_grey.html" class="external-link">scale_fill_grey</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="fu">vip_color</span><span class="op">(</span><span class="va">ames_pretrain</span>, <span class="va">col_with_missings</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="ames_pretrain_vip.png" alt="ames_fit model variable importance plot"><div class="figcaption">ames_fit model variable importance plot</div>
</div>
<p>We get <code>BsmtFin_Type_1</code>, <code>BsmtFin_SF_1</code> and
<code>Bsmt_Exposure</code> variables in the top ten important variables
according to this run of pretraining the model. Those variables has been
screened as having few missing values.</p>
<p>Note that this result varies a lot from run to run. The captured
result here depends a lot on your initialization conditions.</p>
</div>
<div class="section level3">
<h3 id="variable-importance-with-ames_missing-dataset">Variable importance with <code>ames_missing</code> dataset<a class="anchor" aria-label="anchor" href="#variable-importance-with-ames_missing-dataset"></a>
</h3>
<p>Let’s pretrain a new model with the same hyperparameter, but now
using the <code>ames_missing</code> dataset.<br>
In order to compensate the 13% missingness already present in the
<code>ames_missing</code> dataset, we adjust the
<code>pretraining_ratio</code> parameter to
<code>0.5 - 0.13 = 0.37</code></p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ames_missing_rec</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://recipes.tidymodels.org/reference/recipe.html" class="external-link">recipe</a></span><span class="op">(</span><span class="va">Sale_Price</span> <span class="op">~</span> <span class="va">.</span>, data<span class="op">=</span><span class="va">ames_missing</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> </span>
<span>  <span class="fu"><a href="https://recipes.tidymodels.org/reference/step_normalize.html" class="external-link">step_normalize</a></span><span class="op">(</span><span class="fu"><a href="https://recipes.tidymodels.org/reference/has_role.html" class="external-link">all_numeric</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">ames_missing_pretrain</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/tabnet_pretrain.html">tabnet_pretrain</a></span><span class="op">(</span><span class="va">ames_missing_rec</span>, data<span class="op">=</span><span class="va">ames_missing</span>, epoch<span class="op">=</span><span class="fl">50</span>, </span>
<span>                                    cat_emb_dim <span class="op">=</span> <span class="va">cat_emb_dim</span>,</span>
<span>                                    valid_split <span class="op">=</span> <span class="fl">0.2</span>, verbose<span class="op">=</span><span class="cn">TRUE</span>, batch<span class="op">=</span><span class="fl">2930</span>, </span>
<span>                                    pretraining_ratio<span class="op">=</span><span class="fl">0.37</span>, </span>
<span>                                    early_stopping_patience <span class="op">=</span> <span class="fl">3L</span>, early_stopping_tolerance <span class="op">=</span> <span class="fl">1e-4</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html" class="external-link">autoplot</a></span><span class="op">(</span><span class="va">ames_missing_pretrain</span><span class="op">)</span></span>
<span><span class="fu">vip_color</span><span class="op">(</span><span class="va">ames_missing_pretrain</span>, <span class="va">col_with_missings</span><span class="op">)</span></span></code></pre></div>
<pre><code>[Epoch 001] Loss: 56.250610 Valid loss: 40321308.000000
[Epoch 002] Loss: 44.254524 Valid loss: 39138240.000000
[Epoch 003] Loss: 33.992207 Valid loss: 38648800.000000
[Epoch 004] Loss: 26.421488 Valid loss: 37445656.000000
[Epoch 005] Loss: 22.290133 Valid loss: 35814052.000000
...
[Epoch 021] Loss: 10.877335 Valid loss: 20903176.000000
[Epoch 022] Loss: 11.023649 Valid loss: 20772972.000000
[Epoch 023] Loss: 10.819239 Valid loss: 20642806.000000
[Epoch 024] Loss: 10.994371 Valid loss: 20575458.000000
[Epoch 025] Loss: 10.700000 Valid loss: 20449918.000000
[Epoch 026] Loss: 10.902529 Valid loss: 20680102.000000
[Epoch 027] Loss: 10.791571 Valid loss: 20849496.000000
[Epoch 028] Loss: 11.102308 Valid loss: 20995910.000000
Early stopping at epoch 028</code></pre>
<p><img src="ames_missing_pretrain.png" alt="ames_missing_pretrain model training diagnostic plot"><img src="ames_missing_pretrain_vip.png" alt="ames_missing_pretrain model variable importance plot"></p>
<p>We can see here no variables with high missingness is present in the
top 10 important variables. This seems to be a good sign of the model
having captured proper interactions between variables.</p>
</div>
</div>
<div class="section level2">
<h2 id="model-training">Model training<a class="anchor" aria-label="anchor" href="#model-training"></a>
</h2>
<div class="section level3">
<h3 id="variable-importance-with-raw-ames-dataset-1">Variable importance with raw <code>ames</code> dataset<a class="anchor" aria-label="anchor" href="#variable-importance-with-raw-ames-dataset-1"></a>
</h3>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ames_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/tabnet_pretrain.html">tabnet_pretrain</a></span><span class="op">(</span><span class="va">ames_rec</span>, data<span class="op">=</span><span class="va">ames</span>,  tabnet_model <span class="op">=</span> <span class="va">ames_pretrain</span>, </span>
<span>                            epoch<span class="op">=</span><span class="fl">50</span>, cat_emb_dim <span class="op">=</span> <span class="va">cat_emb_dim</span>,</span>
<span>                            valid_split <span class="op">=</span> <span class="fl">0.2</span>, verbose<span class="op">=</span><span class="cn">TRUE</span>, batch<span class="op">=</span><span class="fl">2930</span>, </span>
<span>                            early_stopping_patience <span class="op">=</span> <span class="fl">5L</span>, early_stopping_tolerance <span class="op">=</span> <span class="fl">1e-4</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html" class="external-link">autoplot</a></span><span class="op">(</span><span class="va">ames_fit</span><span class="op">)</span></span>
<span><span class="fu">vip_color</span><span class="op">(</span><span class="va">ames_fit</span>, <span class="va">col_with_missings</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="ames_fit.png" alt="ames_fit model training diagnostic plot"><div class="figcaption">ames_fit model training diagnostic plot</div>
</div>
<p><img src="ames_fit_vip_.png" alt="ames_fit model training variable importance plot"> Here again,
the model uses two predictors <code>BasmFin_SF_2</code> and
<code>Garage_Finish</code> that have respectively 88 % and 5 %
missingness.</p>
</div>
<div class="section level3">
<h3 id="variable-importance-with-ames_missing-dataset-1">Variable importance with <code>ames_missing</code> dataset<a class="anchor" aria-label="anchor" href="#variable-importance-with-ames_missing-dataset-1"></a>
</h3>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ames_missing_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/tabnet_pretrain.html">tabnet_pretrain</a></span><span class="op">(</span><span class="va">ames_rec</span>, data<span class="op">=</span><span class="va">ames_missing</span>,  tabnet_model <span class="op">=</span> <span class="va">ames_missing_pretrain</span>, </span>
<span>                            epoch<span class="op">=</span><span class="fl">50</span>, cat_emb_dim <span class="op">=</span> <span class="va">cat_emb_dim</span>,</span>
<span>                            valid_split <span class="op">=</span> <span class="fl">0.2</span>, verbose<span class="op">=</span><span class="cn">TRUE</span>, batch<span class="op">=</span><span class="fl">2930</span>, </span>
<span>                            early_stopping_patience <span class="op">=</span> <span class="fl">5L</span>, early_stopping_tolerance <span class="op">=</span> <span class="fl">1e-4</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html" class="external-link">autoplot</a></span><span class="op">(</span><span class="va">ames_missing_fit</span><span class="op">)</span></span>
<span><span class="fu">vip_color</span><span class="op">(</span><span class="va">ames_missing_fit</span>, <span class="va">col_with_missings</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="ames_missing_fit.png" alt="ames_fit model training diagnostic plot"><div class="figcaption">ames_fit model training diagnostic plot</div>
</div>
<p><img src="ames_missing_fit_vip.png" alt="ames_fit model training variable importance plot"> Here we can
see one predictors <code>Garage_Area</code> with 5 % missingness in the
top 10.</p>
</div>
</div>
<div class="section level2">
<h2 id="conclusion">Conclusion<a class="anchor" aria-label="anchor" href="#conclusion"></a>
</h2>
<p>Even if the models have a huge variability in the variable importance
among different training, we have the intuition that model trained with
explicit missing data will provide better result than its counterpart
trained with zero-imputed variables.</p>
<p>In any case, having the capability to pretrain and fit TabNet models
with MAR dataset or MNAR dataset is of high convenience for the
real-life use-cases.</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

      </div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Daniel Falbel, Christophe Regouby.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.0.</p>
</div>

      </footer>
</div>






  </body>
</html>
